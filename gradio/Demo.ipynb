{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/meti-94/BERT-QA/blob/main/gradio/Demo.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nuoSH_kvvBfA",
        "outputId": "8e79552a-115b-463c-d0e0-77db81de1fbd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Repository: 'deb https://ppa.launchpadcontent.net/savoury1/ffmpeg4/ubuntu/ jammy main'\n",
            "Description:\n",
            "FFmpeg 4.4.4 builds (& associated multimedia packages) for Xenial & newer.\n",
            "\n",
            "*** Anyone interested in full builds of FFmpeg 4.4.x including all \"bells and whistles\" needs to have donated, after which access to the new private PPA can be requested. See my Launchpad page linked below for details. ***\n",
            "\n",
            "*** Please always see https://launchpad.net/~savoury1 for general updates about this Launchpad site before contacting me or reporting any bugs! ***\n",
            "\n",
            "*** Big thanks to all those who have donated to support this project, you are very directly helping to keep it alive! To all who have not donated: please do so if you can afford it, this project depends on donations. ***\n",
            "\n",
            "If software at this site is useful to you then please consider a donation:\n",
            "\n",
            "*** Donations: https://paypal.me/Savoury1 & https://ko-fi.com/Savoury1 ***\n",
            "*** Also https://patreon.com/Savoury1 & https://liberapay.com/Savoury1 ***\n",
            "\n",
            "Update (5 Apr 2023): FFmpeg 4.4 builds from today onwards are now generic, in that they are similar to current Ubuntu 22.04 Jammy FFmpeg builds. All of the dated updates below still apply to the FFmpeg 4.x builds available at a private \"subscriber only\" PPA (ppa:savoury1/ffmpeg) for supporters.\n",
            "\n",
            "Update (24 Jan 2023): FFmpeg 4.4 builds now have AMD AMF (Advanced Media Framework) support, using latest headers from AMF 1.4.29 (released today).\n",
            "\n",
            "Update (23 Oct 2022): FFmpeg 4.4 builds now have rav1e (new Rust-based AV1 encoder) support & are also built with nv-codec-headers 11.1.5.1 (latest).\n",
            "\n",
            "Update (6 Apr 2022): FFmpeg 4.4 builds now have Netflix VMAF support, with thanks to Frank B. (equal #1 patron of these PPAs) for suggesting/testing!\n",
            "\n",
            "Update (8 May 2021): FFmpeg 4.4 uploads from today onwards are built with these additional optional libraries: glslang (shader support), SVT-AV1 (scalable AV1 encoder), zimg (scaling, colorspace conversion, dithering), Vulkan (GPU acceleration on supported hardware), and SMB (Samba sharing).\n",
            "\n",
            "==========================================================================\n",
            "                   FFmpeg 4 - media tool (Xenial & newer)\n",
            "==========================================================================\n",
            "\n",
            "aom (3.6.1), aribb24 (1.0.3+git20160115), chafa (1.12.4), chromaprint (1.5.1), cjson (1.7.15), codec2 (1.0.5), cppzmq (4.9.0), dav1d (1.2.1), ffmpeg (4.4.4), ffms2 (2.23), flac (1.4.3), fluidsynth (2.3.3), fontconfig (2.13.1), freeglut (3.4.0), freetype (2.11.1), gnutls28 (3.7.3), gpac (2.0.0), gst-{libav,python}1.0 (1.20.6 for gst*), gst-plugins-{bad,base,good,ugly}1.0, gstreamer{-vaapi,1.0}, harfbuzz (6.0.0), ilmbase (3.1.9 = imath), intel-gmmlib (22.3.10), intel-media{-driver,-driver-non-free} (23.2.4), intel-mediasdk (23.2.2), lensfun (0.3.3), libass (0.16.0), libbluray (1.3.4), libbs2b (3.1.0), libcamera (0.1.0), libcdio (2.1.0), libcdio-paranoia (10.2+2.0.1), libdvdnav (6.1.1), libdvdread (6.1.3), libevent (2.1.12-stable), libffado (2.4.7), libfreeaptx (0.1.1), libgcrypt20 (1.10.2), libgsm (1.0.19), libinstpatch (1.1.6), liblc3 (1.0.1), libldac (2.0.2.3+git20200429), libmysofa (1.3.1), libnice (0.1.21), libopenaptx (0.2.0), libopenmpt (0.7.2), libpng1.6 (1.6.40), librabbitmq (0.10.0), libsdl2 (2.28.2), libsodium (1.0.18+git20220815), libsrtp2 (2.5.0), libtasn1-6 (4.18.0), libudfread (1.1.2), libunistring (1.0), libunwind (1.3.2), libva{-utils} (2.19.0), libvpx (1.12.0), libwebm (1.0.0.30), libwebp (1.3.2), libxfixes (6.0.0), libyaml (0.2.5), libyuv (0.0.1857), mbedtls (2.28.2), mpg123 (1.31.2), nettle (3.7.3), norm (1.5.9), openal-soft (1.22.2), openexr (3.1.11), openh264 (2.3.0), openjpeg2 (2.5.0), opus (1.3.1), orc (0.4.33), pipewire (0.3.79), pipewire-media-session (0.4.2), rubberband (3.1.2), snappy (1.1.10), sndio (1.9.0), soundtouch (2.3.1), speex{dsp} (1.2.0), srt (1.5.3), timgm6mb-soundfont, unbound (1.16.2), ust (2.13.4), wavpack (5.6.0), x264 (0.164.3101 = libx264-164), x265 (3.5 = libx265-199), zeromq3 (4.3.4), zimg (3.0.4), zxing-cpp (1.2.0)\n",
            "\n",
            "Focal & Jammy: wireplumber (0.4.14 requires GLib >= 2.62)\n",
            "\n",
            "Focal only: libdecor-0 (0.1.0 for libsdl2 >= 2.0.20)\n",
            "\n",
            "Xenial & Bionic: alsa-{lib,plugins,tools,topology-conf,ucm-conf,utils} (1.2.2), alsa-oss (1.1.8), alsa-plugins-extra (1.1.0), alsaequal (0.6), fftw3 (3.3.8), fribidi (1.0.8), lcms2 (2.9), leptonlib (1.79.0), libgpg-error, libssh, libvidstab (1.1.0), p11-kit, tesseract (4.1.1), wayland-protocols (1.18), webrtc-audio-processing (0.3.1), wildmidi (0.4.3), zlib\n",
            "\n",
            "Xenial only: autogen, curl, gcc-7 (7.5.0), glib2.0 (2.56.4), gobject-introspection (1.56.1), json-glib (1.4.2), lame (3.100), libidn2, libpsl, lm-sensors (3.6.0), mesa (18.0.5 rebuild for newer Wayland), nghttp2, openssl, pysimplesoap, python-{boto,httplib2,imaplib2} (compat with newer openssl), readline (7.0), unbound, wayland (1.16.0)\n",
            "\n",
            "==========================================================================\n",
            "\n",
            "*** Install ***\n",
            "\n",
            "FFmpeg can be installed from this PPA alone, as the required packages to satisfy minimum versions have been copied here (notify me if any missing). However, if _all_ newest versions of graphics and multimedia packages are desired then two additional PPAs can be added before installing FFmpeg:\n",
            "\n",
            "  sudo add-apt-repository ppa:savoury1/graphics\n",
            "  sudo add-apt-repository ppa:savoury1/multimedia\n",
            "  sudo add-apt-repository ppa:savoury1/ffmpeg4\n",
            "  sudo apt-get update\n",
            "  sudo apt-get upgrade && sudo apt-get dist-upgrade\n",
            "  sudo apt-get install ffmpeg\n",
            "\n",
            "Notes: GStreamer 1.20.x packages are copied here (ppa:savoury1/multimedia) as FFmpeg and GStreamer must both be built against the Debian SRT package version with renamed libsrt1.5-gnutls or they cannot both be installed at the same time. GStreamer is on basically every Ubuntu-based system so this means it is necessary to upgrade GStreamer packages when upgrading FFmpeg.\n",
            "\n",
            "Also, PipeWire 0.3.x packages are copied here from the multimedia PPA due PipeWire now being commonly used by various software. As the FFmpeg 4 PPA is required by numerous PPAs at this Launchpad site it makes the latest PipeWire readily available to all users. PipeWire is built with ALSA 1.2.2 minimum (Focal, backported to Xenial & Bionic) which is then required to run, so base ALSA packages are now also copied here for Xenial & Bionic.\n",
            "\n",
            "* Xenial systems: As of FFmpeg 4.3 the installation requires GCC >= 7 as the Intel-MediaSDK is enabled, with libmfx1 requiring GCC >= 7 (package fails to build with GCC 5.4.0). So GCC 7.5.0 (ppa:savoury1/toolchain) for Xenial has been copied here, making it easier to install FFmpeg 4.x on Xenial (so adding this FFmpeg 4 PPA will bring a few GCC 7.5.0 upgrades).\n",
            "\n",
            "* Focal systems: Builds of FFmpeg are now also available for i386 whereas they were not available initially. Launchpad does not build most packages for i386 architecture for Focal and newer series (Launchpad only builds i386 packages on a whitelist managed by the Launchpad team) including for dav1d and pocketsphinx, so these features are not enabled for Focal i386.\n",
            "\n",
            "*** Build ***\n",
            "\n",
            "This PPA has build dependencies on:\n",
            "\n",
            "  ppa:savoury1/build-tools\n",
            "  ppa:savoury1/backports\n",
            "  ppa:savoury1/fonts\n",
            "  ppa:savoury1/graphics\n",
            "  ppa:savoury1/multimedia\n",
            "\n",
            "Additionally, for Xenial builds only:\n",
            "\n",
            "  ppa:savoury1/perl-xenial\n",
            "\n",
            "*** Credits ***\n",
            "\n",
            "- Creators of FFmpeg: Michael Niedermayer and the entire FFmpeg team\n",
            "  https://github.com/FFmpeg/FFmpeg/graphs/contributors\n",
            "\n",
            "- Package code: Debian Multimedia Maintainers\n",
            "  https://tracker.debian.org/pkg/ffmpeg\n",
            "More info: https://launchpad.net/~savoury1/+archive/ubuntu/ffmpeg4\n",
            "Adding repository.\n",
            "Adding deb entry to /etc/apt/sources.list.d/savoury1-ubuntu-ffmpeg4-jammy.list\n",
            "Adding disabled deb-src entry to /etc/apt/sources.list.d/savoury1-ubuntu-ffmpeg4-jammy.list\n",
            "Adding key to /etc/apt/trusted.gpg.d/savoury1-ubuntu-ffmpeg4.gpg with fingerprint E996735927E427A733BB653E374C7797FB006459\n",
            "Hit:1 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Get:2 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [119 kB]\n",
            "Get:3 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease [3,626 B]\n",
            "Get:4 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease [1,581 B]\n",
            "Get:5 http://archive.ubuntu.com/ubuntu jammy-backports InRelease [109 kB]\n",
            "Get:6 http://security.ubuntu.com/ubuntu jammy-security InRelease [110 kB]\n",
            "Hit:7 https://ppa.launchpadcontent.net/c2d4u.team/c2d4u4.0+/ubuntu jammy InRelease\n",
            "Get:8 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  Packages [498 kB]\n",
            "Get:9 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 Packages [1,260 kB]\n",
            "Get:10 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 Packages [1,283 kB]\n",
            "Get:11 http://archive.ubuntu.com/ubuntu jammy-backports/universe amd64 Packages [32.7 kB]\n",
            "Get:12 http://archive.ubuntu.com/ubuntu jammy-backports/main amd64 Packages [78.4 kB]\n",
            "Hit:13 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Get:14 http://security.ubuntu.com/ubuntu jammy-security/main amd64 Packages [1,014 kB]\n",
            "Hit:15 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Get:16 https://ppa.launchpadcontent.net/savoury1/ffmpeg4/ubuntu jammy InRelease [18.1 kB]\n",
            "Get:17 http://security.ubuntu.com/ubuntu jammy-security/universe amd64 Packages [998 kB]\n",
            "Hit:18 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Get:19 https://ppa.launchpadcontent.net/savoury1/ffmpeg4/ubuntu jammy/main amd64 Packages [80.4 kB]\n",
            "Fetched 5,606 kB in 3s (2,009 kB/s)\n",
            "Reading package lists... Done\n",
            "(Reading database ... 120895 files and directories currently installed.)\n",
            "Preparing to unpack .../00-libavformat-dev_7%3a4.4.4-0ubuntu1~22.04.sav1_amd64.deb ...\n",
            "Unpacking libavformat-dev:amd64 (7:4.4.4-0ubuntu1~22.04.sav1) over (7:4.4.2-0ubuntu0.22.04.1) ...\n",
            "Preparing to unpack .../01-libavcodec-dev_7%3a4.4.4-0ubuntu1~22.04.sav1_amd64.deb ...\n",
            "Unpacking libavcodec-dev:amd64 (7:4.4.4-0ubuntu1~22.04.sav1) over (7:4.4.2-0ubuntu0.22.04.1) ...\n",
            "Preparing to unpack .../02-libswresample-dev_7%3a4.4.4-0ubuntu1~22.04.sav1_amd64.deb ...\n",
            "Unpacking libswresample-dev:amd64 (7:4.4.4-0ubuntu1~22.04.sav1) over (7:4.4.2-0ubuntu0.22.04.1) ...\n",
            "Preparing to unpack .../03-ffmpeg_7%3a4.4.4-0ubuntu1~22.04.sav1_amd64.deb ...\n",
            "Unpacking ffmpeg (7:4.4.4-0ubuntu1~22.04.sav1) over (7:4.4.2-0ubuntu0.22.04.1) ...\n",
            "Preparing to unpack .../04-libavdevice58_7%3a4.4.4-0ubuntu1~22.04.sav1_amd64.deb ...\n",
            "Unpacking libavdevice58:amd64 (7:4.4.4-0ubuntu1~22.04.sav1) over (7:4.4.2-0ubuntu0.22.04.1) ...\n",
            "Preparing to unpack .../05-libavfilter7_7%3a4.4.4-0ubuntu1~22.04.sav1_amd64.deb ...\n",
            "Unpacking libavfilter7:amd64 (7:4.4.4-0ubuntu1~22.04.sav1) over (7:4.4.2-0ubuntu0.22.04.1) ...\n",
            "Preparing to unpack .../06-libavformat58_7%3a4.4.4-0ubuntu1~22.04.sav1_amd64.deb ...\n",
            "Unpacking libavformat58:amd64 (7:4.4.4-0ubuntu1~22.04.sav1) over (7:4.4.2-0ubuntu0.22.04.1) ...\n",
            "Preparing to unpack .../07-libavcodec58_7%3a4.4.4-0ubuntu1~22.04.sav1_amd64.deb ...\n",
            "Unpacking libavcodec58:amd64 (7:4.4.4-0ubuntu1~22.04.sav1) over (7:4.4.2-0ubuntu0.22.04.1) ...\n",
            "Preparing to unpack .../08-libswresample3_7%3a4.4.4-0ubuntu1~22.04.sav1_amd64.deb ...\n",
            "Unpacking libswresample3:amd64 (7:4.4.4-0ubuntu1~22.04.sav1) over (7:4.4.2-0ubuntu0.22.04.1) ...\n",
            "Preparing to unpack .../09-libpostproc55_7%3a4.4.4-0ubuntu1~22.04.sav1_amd64.deb ...\n",
            "Unpacking libpostproc55:amd64 (7:4.4.4-0ubuntu1~22.04.sav1) over (7:4.4.2-0ubuntu0.22.04.1) ...\n",
            "Preparing to unpack .../10-libswscale-dev_7%3a4.4.4-0ubuntu1~22.04.sav1_amd64.deb ...\n",
            "Unpacking libswscale-dev:amd64 (7:4.4.4-0ubuntu1~22.04.sav1) over (7:4.4.2-0ubuntu0.22.04.1) ...\n",
            "Preparing to unpack .../11-libswscale5_7%3a4.4.4-0ubuntu1~22.04.sav1_amd64.deb ...\n",
            "Unpacking libswscale5:amd64 (7:4.4.4-0ubuntu1~22.04.sav1) over (7:4.4.2-0ubuntu0.22.04.1) ...\n",
            "Preparing to unpack .../12-libavutil-dev_7%3a4.4.4-0ubuntu1~22.04.sav1_amd64.deb ...\n",
            "Unpacking libavutil-dev:amd64 (7:4.4.4-0ubuntu1~22.04.sav1) over (7:4.4.2-0ubuntu0.22.04.1) ...\n",
            "Preparing to unpack .../13-libavutil56_7%3a4.4.4-0ubuntu1~22.04.sav1_amd64.deb ...\n",
            "Unpacking libavutil56:amd64 (7:4.4.4-0ubuntu1~22.04.sav1) over (7:4.4.2-0ubuntu0.22.04.1) ...\n",
            "Preparing to unpack .../14-libsndio7.0_1.9.0-0.3~22.04.sav0_amd64.deb ...\n",
            "Unpacking libsndio7.0:amd64 (1.9.0-0.3~22.04.sav0) over (1.8.1-1.1) ...\n",
            "Selecting previously unselected package libsndio7:amd64.\n",
            "Preparing to unpack .../15-libsndio7_1.9.0-0.3~22.04.sav0_amd64.deb ...\n",
            "Unpacking libsndio7:amd64 (1.9.0-0.3~22.04.sav0) ...\n",
            "Preparing to unpack .../16-librubberband2_3.1.2+dfsg0-1~22.04.sav0_amd64.deb ...\n",
            "Unpacking librubberband2:amd64 (3.1.2+dfsg0-1~22.04.sav0) over (2.0.0-2) ...\n",
            "Selecting previously unselected package libsrt1.5-gnutls:amd64.\n",
            "Preparing to unpack .../17-libsrt1.5-gnutls_1.5.3-0ubuntu1~22.04.sav0_amd64.deb ...\n",
            "Unpacking libsrt1.5-gnutls:amd64 (1.5.3-0ubuntu1~22.04.sav0) ...\n",
            "Preparing to unpack .../18-libcodec2-1.0_1.0.5-1ubuntu2~22.04.sav0_amd64.deb ...\n",
            "Unpacking libcodec2-1.0:amd64 (1.0.5-1ubuntu2~22.04.sav0) over (1.0.1-3) ...\n",
            "Preparing to unpack .../19-libsnappy1v5_1.1.10-1~22.04.sav0_amd64.deb ...\n",
            "Unpacking libsnappy1v5:amd64 (1.1.10-1~22.04.sav0) over (1.1.8-1build3) ...\n",
            "Preparing to unpack .../20-libvpx7_1.12.0-1ubuntu1~22.04.sav0_amd64.deb ...\n",
            "Unpacking libvpx7:amd64 (1.12.0-1ubuntu1~22.04.sav0) over (1.11.0-2ubuntu2) ...\n",
            "Selecting previously unselected package libx264-164:amd64.\n",
            "Preparing to unpack .../21-libx264-164_2%3a0.164.3101+gitb093bbe-0ubuntu1~22.04.sav0_amd64.deb ...\n",
            "Unpacking libx264-164:amd64 (2:0.164.3101+gitb093bbe-0ubuntu1~22.04.sav0) ...\n",
            "Setting up libcodec2-1.0:amd64 (1.0.5-1ubuntu2~22.04.sav0) ...\n",
            "Setting up libx264-164:amd64 (2:0.164.3101+gitb093bbe-0ubuntu1~22.04.sav0) ...\n",
            "Setting up libavutil56:amd64 (7:4.4.4-0ubuntu1~22.04.sav1) ...\n",
            "Setting up libsnappy1v5:amd64 (1.1.10-1~22.04.sav0) ...\n",
            "Setting up libpostproc55:amd64 (7:4.4.4-0ubuntu1~22.04.sav1) ...\n",
            "Setting up librubberband2:amd64 (3.1.2+dfsg0-1~22.04.sav0) ...\n",
            "Setting up libsrt1.5-gnutls:amd64 (1.5.3-0ubuntu1~22.04.sav0) ...\n",
            "Setting up libvpx7:amd64 (1.12.0-1ubuntu1~22.04.sav0) ...\n",
            "Setting up libswscale5:amd64 (7:4.4.4-0ubuntu1~22.04.sav1) ...\n",
            "Setting up libsndio7:amd64 (1.9.0-0.3~22.04.sav0) ...\n",
            "Setting up libavutil-dev:amd64 (7:4.4.4-0ubuntu1~22.04.sav1) ...\n",
            "Setting up libswresample3:amd64 (7:4.4.4-0ubuntu1~22.04.sav1) ...\n",
            "Setting up libswscale-dev:amd64 (7:4.4.4-0ubuntu1~22.04.sav1) ...\n",
            "Setting up libsndio7.0:amd64 (1.9.0-0.3~22.04.sav0) ...\n",
            "Setting up libavcodec58:amd64 (7:4.4.4-0ubuntu1~22.04.sav1) ...\n",
            "Setting up libswresample-dev:amd64 (7:4.4.4-0ubuntu1~22.04.sav1) ...\n",
            "Setting up libavformat58:amd64 (7:4.4.4-0ubuntu1~22.04.sav1) ...\n",
            "Setting up libavcodec-dev:amd64 (7:4.4.4-0ubuntu1~22.04.sav1) ...\n",
            "Setting up libavformat-dev:amd64 (7:4.4.4-0ubuntu1~22.04.sav1) ...\n",
            "Setting up libavfilter7:amd64 (7:4.4.4-0ubuntu1~22.04.sav1) ...\n",
            "Setting up libavdevice58:amd64 (7:4.4.4-0ubuntu1~22.04.sav1) ...\n",
            "Setting up ffmpeg (7:4.4.4-0ubuntu1~22.04.sav1) ...\n",
            "Processing triggers for man-db (2.10.2-1) ...\n",
            "Processing triggers for libc-bin (2.35-0ubuntu3.1) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_0.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbb.so.12 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc_proxy.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_5.so.3 is not a symbolic link\n",
            "\n"
          ]
        }
      ],
      "source": [
        "! add-apt-repository -y ppa:savoury1/ffmpeg4\n",
        "! apt-get -qq install -y ffmpeg"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4cPB8R5LRLXC",
        "outputId": "91b57985-a8b0-4453-9ea2-d53d5cac32b3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m20.2/20.2 MB\u001b[0m \u001b[31m57.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.2/66.2 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m298.2/298.2 kB\u001b[0m \u001b[31m24.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.7/75.7 kB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m294.9/294.9 kB\u001b[0m \u001b[31m23.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m138.7/138.7 kB\u001b[0m \u001b[31m13.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.7/45.7 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.5/59.5 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.9/129.9 kB\u001b[0m \u001b[31m12.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.6/17.6 MB\u001b[0m \u001b[31m69.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m74.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.0/67.0 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.0/76.0 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m53.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for DeepImageSearch (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for ffmpy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting git+https://github.com/openai/whisper.git\n",
            "  Cloning https://github.com/openai/whisper.git to /tmp/pip-req-build-l9g4hf5i\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/openai/whisper.git /tmp/pip-req-build-l9g4hf5i\n",
            "  Resolved https://github.com/openai/whisper.git to commit 0a60fcaa9b86748389a656aa013c416030287d47\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20230918) (2.0.0)\n",
            "Requirement already satisfied: numba in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20230918) (0.56.4)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20230918) (1.23.5)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20230918) (2.0.1+cu118)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20230918) (4.66.1)\n",
            "Requirement already satisfied: more-itertools in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20230918) (10.1.0)\n",
            "Collecting tiktoken==0.3.3 (from openai-whisper==20230918)\n",
            "  Downloading tiktoken-0.3.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m17.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken==0.3.3->openai-whisper==20230918) (2023.6.3)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from tiktoken==0.3.3->openai-whisper==20230918) (2.31.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->openai-whisper==20230918) (3.27.4.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->openai-whisper==20230918) (3.12.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->openai-whisper==20230918) (16.0.6)\n",
            "Requirement already satisfied: llvmlite<0.40,>=0.39.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba->openai-whisper==20230918) (0.39.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from numba->openai-whisper==20230918) (67.7.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20230918) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20230918) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20230918) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20230918) (3.1.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken==0.3.3->openai-whisper==20230918) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken==0.3.3->openai-whisper==20230918) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken==0.3.3->openai-whisper==20230918) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken==0.3.3->openai-whisper==20230918) (2023.7.22)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->openai-whisper==20230918) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->openai-whisper==20230918) (1.3.0)\n",
            "Building wheels for collected packages: openai-whisper\n",
            "  Building wheel for openai-whisper (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for openai-whisper: filename=openai_whisper-20230918-py3-none-any.whl size=798399 sha256=3c11451dee4be04e1585c481e1ef2df185d03a5429325209d4b2c2a51d17e1be\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-97ciyx0o/wheels/8b/6c/d0/622666868c179f156cf595c8b6f06f88bc5d80c4b31dccaa03\n",
            "Successfully built openai-whisper\n",
            "Installing collected packages: tiktoken, openai-whisper\n",
            "Successfully installed openai-whisper-20230918 tiktoken-0.3.3\n"
          ]
        }
      ],
      "source": [
        "!pip install gradio gtts DeepImageSearch -q\n",
        "!pip install git+https://github.com/openai/whisper.git"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "token = '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'\n",
        "!git clone https://{token}@github.com/MatGhazi/VisionAi.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pMv7_V1lOB7c",
        "outputId": "55fc8b6b-af49-47f4-81b1-6118110e8383"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'VisionAi'...\n",
            "remote: Enumerating objects: 558, done.\u001b[K\n",
            "remote: Counting objects: 100% (141/141), done.\u001b[K\n",
            "remote: Compressing objects: 100% (112/112), done.\u001b[K\n",
            "remote: Total 558 (delta 52), reused 98 (delta 24), pack-reused 417\u001b[K\n",
            "Receiving objects: 100% (558/558), 49.72 MiB | 25.13 MiB/s, done.\n",
            "Resolving deltas: 100% (103/103), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lvH4RpZRSXzg",
        "outputId": "bd58b941-0e89-472c-9202-98a7d610f051"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[91m Please Wait Model Is Loading or Downloading From Server!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-5-157a92ffc577>:207: GradioDeprecationWarning: 'scale' value should be an integer. Using 0.5 will cause issues.\n",
            "  with gr.Column(scale=0.5):\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[92m Model Loaded Successfully: vgg19\n",
            "\u001b[93m Meta data already Present, Please Apply Search!\n",
            "['image_features_vectors.idx', 'image_data_features.pkl']\n",
            "Colab notebook detected. This cell will run indefinitely so that you can see errors and logs. To turn off, set debug=False in launch().\n",
            "Running on public URL: https://2a6dbd91f838e089e1.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n",
            "Upload Handler is called\n",
            "img size in memory in bytes:  3343443\n",
            "img size in memory in bytes:  92688\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-5-157a92ffc577>:177: DeprecationWarning: ANTIALIAS is deprecated and will be removed in Pillow 10 (2023-07-01). Use LANCZOS or Resampling.LANCZOS instead.\n",
            "  image_to_use = image_to_use.resize((int(h//coe), int(w//coe)), Image.ANTIALIAS)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reset Handler is called\n",
            "Upload Handler is called\n",
            "img size in memory in bytes:  2983713\n",
            "img size in memory in bytes:  119073\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-5-157a92ffc577>:177: DeprecationWarning: ANTIALIAS is deprecated and will be removed in Pillow 10 (2023-07-01). Use LANCZOS or Resampling.LANCZOS instead.\n",
            "  image_to_use = image_to_use.resize((int(h//coe), int(w//coe)), Image.ANTIALIAS)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Keyboard interruption in main thread... closing server.\n",
            "Killing tunnel 127.0.0.1:7860 <> https://2a6dbd91f838e089e1.gradio.live\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "from gradio.components.chatbot import Chatbot\n",
        "from sre_constants import LITERAL\n",
        "import gradio as gr\n",
        "import whisper\n",
        "from gtts import gTTS\n",
        "import sys\n",
        "####################\n",
        "from DeepImageSearch import Load_Data, Search_Setup\n",
        "from PIL import Image\n",
        "import faiss\n",
        "import DeepImageSearch.config as config\n",
        "import numpy as np\n",
        "import json\n",
        "import os\n",
        "import pandas as pd\n",
        "\n",
        "class My_Load_Data(Load_Data):\n",
        "    def from_json(self, json_file_path: str, images_column_name: str, prefix='/content/VisionAi/utilities/scraper/data/'):\n",
        "        self.json_file_path = json_file_path\n",
        "        self.images_column_name = images_column_name\n",
        "        return pd.read_json(self.json_file_path)[self.images_column_name].apply(lambda item:prefix+item).to_list()\n",
        "\n",
        "class My_Search_Setup(Search_Setup):\n",
        "    def _search_by_vector(self, v, n: int):\n",
        "        self.v = v\n",
        "        self.n = n\n",
        "        index = faiss.read_index(config.image_features_vectors_idx(self.model_name))\n",
        "        D, I = index.search(np.array([self.v], dtype=np.float32), self.n)\n",
        "        return dict(zip(D[0], I[0]))\n",
        "\n",
        "    def get_similar_images(self, image: np.array, number_of_images: int = 10):\n",
        "        self.number_of_images = number_of_images\n",
        "        query_vector = self._extract(image)\n",
        "        img_dict = self._search_by_vector(query_vector, self.number_of_images)\n",
        "        return img_dict\n",
        "    def run_index(self):\n",
        "        if len(os.listdir(f'metadata-files/{self.model_name}')) == 0:\n",
        "            data = self._start_feature_extraction()\n",
        "            self._start_indexing(data)\n",
        "        else:\n",
        "            # print(\"\\033[91m Metadata and Features are already present, Do you want Extract Again? Enter yes or no\")\n",
        "            # flag = str(input())\n",
        "            flag = 'no'\n",
        "            if flag.lower() == 'yes':\n",
        "                data = self._start_feature_extraction()\n",
        "                self._start_indexing(data)\n",
        "            else:\n",
        "                print(\"\\033[93m Meta data already Present, Please Apply Search!\")\n",
        "                print(os.listdir(f'metadata-files/{self.model_name}'))\n",
        "        self.image_data = pd.read_pickle(config.image_data_with_features_pkl(self.model_name))\n",
        "        self.f = len(self.image_data['features'][0])\n",
        "\n",
        "class Chat:\n",
        "    def __init__(self):\n",
        "        pass\n",
        "\n",
        "    def upload_img(self, gr_img, chat_state, img_list):\n",
        "        return None, None, None, chat_state, ['image']\n",
        "\n",
        "    def answer(self, conv, img_list, num_beams, temperature, max_new_tokens=300, max_length=2000):\n",
        "        return 'this is a message from LLM', None\n",
        "\n",
        "    def ask(self, user_message, chat_state):\n",
        "        chat_state.messages.append(user_message)\n",
        "        return chat_state\n",
        "\n",
        "class State:\n",
        "    def __init__(self):\n",
        "        self.messages = []\n",
        "\n",
        "    def copy(self):\n",
        "        return self\n",
        "\n",
        "\n",
        "def load_list_from_json(filename):\n",
        "    \"\"\"\n",
        "    Load a list from a JSON file\n",
        "\n",
        "    :param filename: File path to load the JSON file from\n",
        "    :return: List loaded from the JSON file\n",
        "    \"\"\"\n",
        "    try:\n",
        "        with open(filename, 'r') as json_file:\n",
        "            data = json.load(json_file)\n",
        "            return data\n",
        "    except FileNotFoundError:\n",
        "        print(\"The file could not be found\")\n",
        "    except json.JSONDecodeError:\n",
        "        print(\"The file could not be decoded\")\n",
        "    except Exception as e:\n",
        "        print(f\"An error occurred: {e}\")\n",
        "\n",
        "# Load the links from the JSON file\n",
        "filename = '/content/VisionAi/utilities/scraper/paraphrased_dataset.json'\n",
        "collection = load_list_from_json(filename)\n",
        "\n",
        "# Global variables\n",
        "img_list = []\n",
        "chat = Chat()\n",
        "CONV_VISION = State()\n",
        "model_whisper = whisper.load_model(\"medium\")\n",
        "image_list = My_Load_Data().from_json('/content/VisionAi/utilities/scraper/dataset.json', 'image_name')\n",
        "st = My_Search_Setup(image_list=image_list, model_name='vgg19', pretrained=True, image_count=100)\n",
        "st.run_index()\n",
        "\n",
        "\n",
        "# Define the required functions\n",
        "\n",
        "def historical_info(gr_img, webcam_img, chatbot, threshold=1, default_size=5e5):\n",
        "    print('Image Search Handler is called')\n",
        "    if gr_img is None and webcam_img is None:\n",
        "        return gr.update(value='No image is selected.')\n",
        "    if type(gr_img)==type(None):\n",
        "        image_to_use = webcam_img\n",
        "    else:\n",
        "        image_to_use = gr_img\n",
        "    if isinstance(image_to_use, Image.Image):\n",
        "        image_to_use = np.asarray(image_to_use)\n",
        "    if isinstance(image_to_use, np.ndarray):\n",
        "        image_to_use = Image.fromarray(np.uint8(image_to_use)).convert('RGB')\n",
        "    print(\"img size in memory in bytes: \", sys.getsizeof(image_to_use.tobytes()))\n",
        "    img_size = sys.getsizeof(image_to_use.tobytes())\n",
        "    coe = img_size//default_size\n",
        "    h, w = image_to_use.size\n",
        "    image_to_use = image_to_use.resize((int(h//coe), int(w//coe)), Image.ANTIALIAS)\n",
        "    print(\"img size in memory in bytes: \", sys.getsizeof(image_to_use.tobytes()))\n",
        "    result = st.get_similar_images(image=image_to_use, number_of_images=1)\n",
        "    if list(result.keys())[0]<threshold:\n",
        "        idx = int(list(result.values())[0])\n",
        "        historical_data = collection[idx]['narration']\n",
        "        return chatbot+[['The historical info', historical_data]]\n",
        "    else:\n",
        "        return chatbot+[['The historical info', 'No similar image is found.']]\n",
        "\n",
        "def transcribe(audio, chat_state, chatbot):\n",
        "    print('Transcirbe Handler is called')\n",
        "    text = model_whisper.transcribe(audio)[\"text\"]\n",
        "    print(f'ASR text: {text}')\n",
        "    return text, chat_state, chatbot\n",
        "\n",
        "def tts_response(chatbot):\n",
        "    print('TTS Handler is called')\n",
        "    if chatbot and chatbot[-1][1]:\n",
        "        response = chatbot[-1][1]\n",
        "        tts = gTTS(text=response, lang='en')\n",
        "        filename = \"response.mp3\"\n",
        "        tts.save(filename)\n",
        "        return filename\n",
        "    return None\n",
        "\n",
        "def gradio_reset(chat_state, img_list, audio_output):\n",
        "    print('Reset Handler is called')\n",
        "    if chat_state is not None:\n",
        "        chat_state.messages = []\n",
        "    if img_list is not None:\n",
        "        img_list = []\n",
        "    audio_output = None\n",
        "    audio_input = None\n",
        "    return None, gr.update(value=None, interactive=True), gr.update(placeholder='Please upload your image first', interactive=False), gr.update(value=\"Upload & Start Chat\", interactive=True), chat_state, img_list, audio_output, audio_input\n",
        "\n",
        "def upload_img(gr_img, webcam_img, text_input, chat_state, hst_button, default_size=5e5):\n",
        "    print('Upload Handler is called')\n",
        "    if gr_img is None and webcam_img is None:\n",
        "        return None, None, gr.update(interactive=True), chat_state, None\n",
        "    if type(gr_img)==type(None):\n",
        "        image_to_use = webcam_img\n",
        "    else:\n",
        "        image_to_use = gr_img\n",
        "    if isinstance(image_to_use, Image.Image):\n",
        "        image_to_use = np.asarray(image_to_use)\n",
        "    if isinstance(image_to_use, np.ndarray):\n",
        "        image_to_use = Image.fromarray(np.uint8(image_to_use)).convert('RGB')\n",
        "    print(\"img size in memory in bytes: \", sys.getsizeof(image_to_use.tobytes()))\n",
        "    img_size = sys.getsizeof(image_to_use.tobytes())\n",
        "    coe = img_size//default_size\n",
        "    h, w = image_to_use.size\n",
        "    image_to_use = image_to_use.resize((int(h//coe), int(w//coe)), Image.ANTIALIAS)\n",
        "    print(\"img size in memory in bytes: \", sys.getsizeof(image_to_use.tobytes()))\n",
        "    chat_state = CONV_VISION.copy()\n",
        "    img_list = []\n",
        "    llm_message = chat.upload_img(image_to_use, chat_state, img_list)\n",
        "    return gr.update(interactive=False), gr.update(interactive=True, placeholder='Type and press Enter'), gr.update(value=\"Start Chatting\", interactive=False), chat_state, img_list, gr.update(interactive=True)\n",
        "\n",
        "def gradio_ask(user_message, chatbot, chat_state):\n",
        "    print('Ask Handler is called')\n",
        "    if not user_message:\n",
        "        return gr.update(interactive=True, placeholder='Input should not be empty!'), chatbot, chat_state\n",
        "    chat.ask(user_message, chat_state)\n",
        "    chatbot = chatbot + [[user_message, None]]\n",
        "    return '', chatbot, chat_state\n",
        "\n",
        "def gradio_answer(chatbot, chat_state, img_list, num_beams, temperature):\n",
        "    print('Answer Handler is called')\n",
        "    llm_message = chat.answer(conv=chat_state, img_list=img_list, num_beams=num_beams, temperature=temperature, max_new_tokens=300, max_length=2000)[0]\n",
        "    chatbot[-1][1] = llm_message\n",
        "    return chatbot, chat_state, img_list\n",
        "\n",
        "# Design the Gradio interface\n",
        "with gr.Blocks() as demo:\n",
        "    gr.Markdown(\"<h1 align='center'>Demo of MiniGPT-4</h1>\")\n",
        "    gr.Markdown(\"<h3>This is the demo of MiniGPT-4. Upload your images and start chatting!</h3>\")\n",
        "    gr.Markdown(\"\"\"<p><a href='https://minigpt-4.github.io'><img src='https://img.shields.io/badge/Project-Page-Green'></a>\n",
        "                  <a href='https://github.com/Vision-CAIR/MiniGPT-4'><img src='https://img.shields.io/badge/Github-Code-blue'></a>\n",
        "                  <a href='https://raw.githubusercontent.com/Vision-CAIR/MiniGPT-4/main/MiniGPT_4.pdf'><img src='https://img.shields.io/badge/Paper-PDF-red'></a></p>\"\"\")\n",
        "\n",
        "    with gr.Row():\n",
        "        with gr.Column(scale=0.5):\n",
        "            image = gr.Image(type=\"pil\")\n",
        "            webcam = gr.Webcam()\n",
        "            upload_button = gr.Button(value=\"Upload & Start Chat\")\n",
        "            clear = gr.Button(\"Restart\")\n",
        "            num_beams = gr.Slider(minimum=1, maximum=10, value=1, step=1, label=\"beam search numbers\")\n",
        "            temperature = gr.Slider(minimum=0.1, maximum=2.0, value=1.0, step=0.1, label=\"Temperature\")\n",
        "\n",
        "        with gr.Column():\n",
        "            chat_state = gr.State()\n",
        "            img_list = gr.State()\n",
        "            chatbot = gr.Chatbot(label='MiniGPT-4')\n",
        "            text_input = gr.Textbox(label='User', placeholder='Please upload your image first', interactive=False)\n",
        "            # ASR components\n",
        "            audio_input = gr.Audio(source=\"microphone\", type=\"filepath\")\n",
        "\n",
        "            with gr.Row():  # Combining ASR and TTS buttons in a row\n",
        "                asr_button = gr.Button(\"Transcribe\", size=4)  # Adjusting the size to fit in a row\n",
        "                tts_button = gr.Button(\"Listen to Response\", size=4, interactive=False)  # Adjusting the size to fit in a row\n",
        "                hst_button = gr.Button(\"Historical Data\", size=4, interactive=False)\n",
        "\n",
        "            audio_output = gr.Audio(type=\"filepath\", label=\"Audio Response\")\n",
        "\n",
        "    upload_button.click(upload_img, [image, webcam, text_input, chat_state, hst_button], [image, text_input, upload_button, chat_state, img_list, hst_button])\n",
        "\n",
        "    text_input.submit(gradio_ask, [text_input, chatbot, chat_state], [text_input, chatbot, chat_state]).then(\n",
        "        gradio_answer, [chatbot, chat_state, img_list, num_beams, temperature], [chatbot, chat_state, img_list]).then(\n",
        "            lambda btn: gr.update(interactive=True), [tts_button], [tts_button])\n",
        "    clear.click(gradio_reset, [chat_state, img_list, audio_output], [chatbot, image, text_input, upload_button, chat_state, img_list, audio_output, audio_input], queue=False).then(\n",
        "            lambda btn: gr.update(interactive=False), [tts_button], [tts_button])\n",
        "\n",
        "    # TTS action\n",
        "    tts_button.click(tts_response, [chatbot], [audio_output])\n",
        "\n",
        "    # Binding the transcribe function to the asr_button click action\n",
        "    asr_button.click(transcribe, [audio_input, chat_state, chatbot], [text_input, chat_state, chatbot]).then(\n",
        "        gradio_ask, [text_input, chatbot, chat_state], [text_input, chatbot, chat_state]).then(\n",
        "        gradio_answer, [chatbot, chat_state, img_list, num_beams, temperature], [chatbot, chat_state, img_list]).then(\n",
        "            lambda btn: gr.update(interactive=True), [tts_button], [tts_button]).then(\n",
        "            lambda audioinput: None, [audio_input], [audio_input]\n",
        "            )\n",
        "\n",
        "    # Historical info\n",
        "    hst_button.click(historical_info, [image, webcam, chatbot], [chatbot]).then(\n",
        "        lambda btn: gr.update(interactive=True), [tts_button], [tts_button]\n",
        "    )\n",
        "\n",
        "\n",
        "demo.queue().launch(debug=True, share=True, inline=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ii4dAVFPZVA7"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.17"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}